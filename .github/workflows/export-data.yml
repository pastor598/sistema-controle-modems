name: ðŸ“Š Export Modem Data to CSV & Google Sheets

on:
  schedule:
    # Executar a cada 30 minutos (mais eficiente que 15 min)
    - cron: '*/30 * * * *'
    # Executar diariamente Ã s 9h para relatÃ³rio
    - cron: '0 9 * * *'
    # Executar Ã s 18h para backup
    - cron: '0 18 * * *'
  workflow_dispatch: # Permite execuÃ§Ã£o manual
    inputs:
      force_update:
        description: 'ForÃ§ar atualizaÃ§Ã£o mesmo sem mudanÃ§as'
        required: false
        default: false
        type: boolean
      export_to_sheets:
        description: 'Exportar tambÃ©m para Google Sheets'
        required: false
        default: true
        type: boolean
  push:
    branches: [ main ]
    paths:
      - 'data/**'
      - '.github/workflows/export-data.yml'

env:
  NODE_VERSION: '20'
  DATA_DIR: 'data'
  BACKUP_DIR: 'backups'

jobs:
  export-data:
    name: ðŸš€ Export & Sync Data
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    outputs:
      records-count: ${{ steps.export.outputs.records-count }}
      file-size: ${{ steps.export.outputs.file-size }}
      export-status: ${{ steps.export.outputs.status }}
    
    steps:
    - name: ðŸ“‚ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0 # Buscar histÃ³rico completo para comparaÃ§Ãµes
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: ðŸ”§ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: ðŸ“Š Create enhanced export script
      run: |
        cat > export-data.js << 'EOF'
        const fs = require('fs');
        const path = require('path');
        const { execSync } = require('child_process');
        
        // ConfiguraÃ§Ãµes
        const config = {
          maxRecords: 1000,
          dataDir: process.env.DATA_DIR || 'data',
          backupDir: process.env.BACKUP_DIR || 'backups',
          forceUpdate: process.env.FORCE_UPDATE === 'true'
        };
        
        // FunÃ§Ã£o para log estruturado
        function log(level, message, data = null) {
          const timestamp = new Date().toISOString();
          const logEntry = { timestamp, level, message };
          if (data) logEntry.data = data;
          console.log(JSON.stringify(logEntry));
        }
        
        // FunÃ§Ã£o para gerar dados realistas
        function generateModemData() {
          const modelos = [
            { modelo: "Motorola SB6141", fabricante: "Motorola" },
            { modelo: "ARRIS SB8200", fabricante: "ARRIS" },
            { modelo: "Huawei EG8145V5", fabricante: "Huawei" },
            { modelo: "Nokia G-1425G-B", fabricante: "Nokia" },
            { modelo: "TP-Link Archer C80", fabricante: "TP-Link" },
            { modelo: "Technicolor TC8717T", fabricante: "Technicolor" }
          ];
          
          const observacoes = [
            "GravaÃ§Ã£o padrÃ£o",
            "Teste de qualidade aprovado",
            "Lote de produÃ§Ã£o",
            "ConfiguraÃ§Ã£o personalizada",
            "AtualizaÃ§Ã£o de firmware",
            "Teste de stress completo"
          ];
          
          const today = new Date();
          const records = [];
          
          // Gerar entre 3-8 registros por execuÃ§Ã£o
          const numRecords = Math.floor(Math.random() * 6) + 3;
          
          for (let i = 1; i <= numRecords; i++) {
            const modelo = modelos[Math.floor(Math.random() * modelos.length)];
            const obs = observacoes[Math.floor(Math.random() * observacoes.length)];
            
            records.push({
              id: Date.now() + i,
              data: today.toISOString().split('T')[0],
              modelo: modelo.modelo,
              fabricante: modelo.fabricante,
              quantidade: Math.floor(Math.random() * 20) + 1,
              observacoes: obs,
              timestamp: new Date(today.getTime() + i * 1000).toISOString()
            });
          }
          
          return records;
        }
        
        // FunÃ§Ã£o para converter para CSV robusto
        function arrayToCSV(data) {
          if (!data.length) return '';
          
          const headers = Object.keys(data[0]);
          const csvHeaders = headers.join(',');
          
          const csvRows = data.map(row => 
            headers.map(header => {
              let value = row[header];
              if (value === null || value === undefined) value = '';
              value = String(value);
              
              // Escapar vÃ­rgulas, aspas e quebras de linha
              if (value.includes(',') || value.includes('"') || value.includes('\n')) {
                value = `"${value.replace(/"/g, '""')}"`;
              }
              return value;
            }).join(',')
          );
          
          return [csvHeaders, ...csvRows].join('\n');
        }
        
        // FunÃ§Ã£o para criar backup
        function createBackup() {
          try {
            if (!fs.existsSync(config.backupDir)) {
              fs.mkdirSync(config.backupDir, { recursive: true });
            }
            
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
            const backupFile = path.join(config.backupDir, `modem-data-${timestamp}.csv`);
            
            if (fs.existsSync(path.join(config.dataDir, 'modem-data.csv'))) {
              fs.copyFileSync(
                path.join(config.dataDir, 'modem-data.csv'),
                backupFile
              );
              log('INFO', 'Backup criado', { file: backupFile });
            }
          } catch (error) {
            log('ERROR', 'Falha ao criar backup', { error: error.message });
          }
        }
        
        // FunÃ§Ã£o principal
        async function main() {
          try {
            log('INFO', 'Iniciando exportaÃ§Ã£o de dados');
            
            // Criar diretÃ³rios
            if (!fs.existsSync(config.dataDir)) {
              fs.mkdirSync(config.dataDir, { recursive: true });
            }
            
            // Ler dados existentes
            let existingData = [];
            const csvPath = path.join(config.dataDir, 'modem-data.csv');
            
            if (fs.existsSync(csvPath)) {
              createBackup();
              
              const existingCsv = fs.readFileSync(csvPath, 'utf8');
              const lines = existingCsv.split('\n').filter(line => line.trim());
              
              if (lines.length > 1) {
                const headers = lines[0].split(',');
                existingData = lines.slice(1).map(line => {
                  const values = line.split(',');
                  const record = {};
                  headers.forEach((header, index) => {
                    record[header] = values[index] || '';
                  });
                  return record;
                });
              }
            }
            
            // Gerar novos dados
            const newData = generateModemData();
            log('INFO', 'Novos dados gerados', { count: newData.length });
            
            // Combinar dados (manter Ãºltimos 500 registros)
            const allData = [...existingData, ...newData]
              .slice(-config.maxRecords)
              .sort((a, b) => new Date(b.timestamp) - new Date(a.timestamp));
            
            // Converter para CSV
            const csvContent = arrayToCSV(allData);
            
            // Verificar se houve mudanÃ§as
            const hasChanges = !fs.existsSync(csvPath) || 
                              fs.readFileSync(csvPath, 'utf8') !== csvContent ||
                              config.forceUpdate;
            
            if (hasChanges) {
              // Salvar CSV
              fs.writeFileSync(csvPath, csvContent);
              log('INFO', 'CSV atualizado', { records: allData.length });
              
              // Criar metadata detalhada
              const stats = allData.reduce((acc, record) => {
                acc.manufacturers[record.fabricante] = (acc.manufacturers[record.fabricante] || 0) + parseInt(record.quantidade || 0);
                acc.totalQuantity += parseInt(record.quantidade || 0);
                return acc;
              }, { manufacturers: {}, totalQuantity: 0 });
              
              const metadata = {
                lastUpdate: new Date().toISOString(),
                recordCount: allData.length,
                newRecordsAdded: newData.length,
                version: '2.0',
                source: 'GitHub Actions Enhanced',
                statistics: {
                  totalQuantity: stats.totalQuantity,
                  averagePerRecord: Math.round(stats.totalQuantity / allData.length * 100) / 100,
                  manufacturerDistribution: stats.manufacturers,
                  dateRange: {
                    earliest: allData[allData.length - 1]?.data,
                    latest: allData[0]?.data
                  }
                },
                workflow: {
                  runId: process.env.GITHUB_RUN_ID,
                  runNumber: process.env.GITHUB_RUN_NUMBER,
                  actor: process.env.GITHUB_ACTOR,
                  ref: process.env.GITHUB_REF,
                  sha: process.env.GITHUB_SHA
                }
              };
              
              fs.writeFileSync(
                path.join(config.dataDir, 'metadata.json'),
                JSON.stringify(metadata, null, 2)
              );
              
              // Outputs para o GitHub Actions
              console.log(`::set-output name=records-count::${allData.length}`);
              console.log(`::set-output name=file-size::${Math.round(csvContent.length / 1024 * 100) / 100}`);
              console.log(`::set-output name=status::updated`);
              
              log('SUCCESS', 'ExportaÃ§Ã£o concluÃ­da', {
                totalRecords: allData.length,
                newRecords: newData.length,
                fileSizeKB: Math.round(csvContent.length / 1024 * 100) / 100
              });
              
            } else {
              console.log(`::set-output name=status::no-changes`);
              log('INFO', 'Nenhuma mudanÃ§a detectada');
            }
            
          } catch (error) {
            log('ERROR', 'Falha na exportaÃ§Ã£o', { error: error.message, stack: error.stack });
            console.log(`::set-output name=status::error`);
            process.exit(1);
          }
        }
        
        main();
        EOF
        
    - name: ðŸ“ Create directories
      run: |
        mkdir -p ${{ env.DATA_DIR }}
        mkdir -p ${{ env.BACKUP_DIR }}
        
    - name: ðŸš€ Run enhanced export script
      id: export
      run: node export-data.js
      env:
        FORCE_UPDATE: ${{ github.event.inputs.force_update || 'false' }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_RUN_NUMBER: ${{ github.run_number }}
        GITHUB_ACTOR: ${{ github.actor }}
        GITHUB_REF: ${{ github.ref }}
        GITHUB_SHA: ${{ github.sha }}
        
    - name: ðŸ“ˆ Generate summary report
      if: always()
      run: |
        echo "## ðŸ“Š Export Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Status**: ${{ steps.export.outputs.export-status }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Records**: ${{ steps.export.outputs.records-count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **File Size**: ${{ steps.export.outputs.file-size }} KB" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "- **Workflow**: [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "data/metadata.json" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“‹ Metadata" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat data/metadata.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: ðŸ”„ Commit and push changes
      if: steps.export.outputs.export-status == 'updated'
      run: |
        git config --local user.email "actions@github.com"
        git config --local user.name "GitHub Actions Bot"
        git config --local core.autocrlf false
        
        git add data/ backups/
        
        # Verificar se hÃ¡ mudanÃ§as para commit
        if git diff --staged --quiet; then
          echo "Nenhuma mudanÃ§a para commit"
        else
          # Criar mensagem de commit detalhada
          COMMIT_MSG="ðŸ”„ Dados atualizados automaticamente
          
          ðŸ“Š Registros: ${{ steps.export.outputs.records-count }}
          ðŸ“ Tamanho: ${{ steps.export.outputs.file-size }} KB
          â° Data: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          ðŸ¤– Workflow: #${{ github.run_number }}
          
          [skip ci]"
          
          git commit -m "$COMMIT_MSG"
          git push
          echo "âœ… MudanÃ§as commitadas e enviadas"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
    - name: ðŸ“¤ Export to Google Sheets (Optional)
      if: steps.export.outputs.export-status == 'updated' && (github.event.inputs.export_to_sheets == 'true' || github.event_name == 'schedule')
      uses: jroehl/gsheet.action@v2.1.1
      with:
        spreadsheetId: ${{ secrets.GOOGLE_SHEET_ID }}
        commands: |
          [
            {
              "command": "updateData",
              "args": {
                "data": "${{ env.CSV_DATA }}",
                "worksheetTitle": "ModemData",
                "minRow": 1,
                "minCol": 1,
                "valueInputOption": "RAW"
              }
            }
          ]
      env:
        GSHEET_CLIENT_EMAIL: ${{ secrets.GSHEET_CLIENT_EMAIL }}
        GSHEET_PRIVATE_KEY: ${{ secrets.GSHEET_PRIVATE_KEY }}
        CSV_DATA: ${{ steps.prepare-sheets-data.outputs.data }}
        
    - name: ðŸŽ¯ Prepare data for Google Sheets
      id: prepare-sheets-data
      if: steps.export.outputs.export-status == 'updated'
      run: |
        # Converter CSV para formato JSON array para Google Sheets
        if [ -f "data/modem-data.csv" ]; then
          node -e "
            const fs = require('fs');
            const csv = fs.readFileSync('data/modem-data.csv', 'utf8');
            const lines = csv.split('\n').filter(line => line.trim());
            const data = lines.map(line => line.split(','));
            console.log('::set-output name=data::' + JSON.stringify(data));
          "
        fi
        
    - name: ðŸš¨ Notify on failure
      if: failure()
      run: |
        echo "::error::Workflow falhou! Verifique os logs para mais detalhes."
        echo "## âŒ Export Failed" >> $GITHUB_STEP_SUMMARY
        echo "O workflow de exportaÃ§Ã£o falhou. Verifique os logs acima para detalhes." >> $GITHUB_STEP_SUMMARY
        echo "- **Run ID**: ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY 